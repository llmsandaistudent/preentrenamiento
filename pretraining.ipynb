{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1G5lgv8oB0C5Dc6ZpupdYYZrHe-kgFPZn","timestamp":1714924427153}],"gpuType":"T4","authorship_tag":"ABX9TyNWeu1vwWJ7RW4jLGzmx9H9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torch\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"q6r37w76cYpE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715010202717,"user_tz":360,"elapsed":114363,"user":{"displayName":"AI Student","userId":"00754387130632506558"}},"outputId":"7d68736b-59c7-4294-86ba-ea9bd0bbcc18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n","    requirement_set = resolver.resolve(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n","    result = self._result = resolver.resolve(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n","    state = resolution.resolve(requirements, max_rounds=max_rounds)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n","    failure_causes = self._attempt_to_pin_criterion(name)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n","    criteria = self._get_updated_criteria(candidate)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n","    self._add_to_criteria(criteria, requirement, parent=candidate)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n","    if not criterion.candidates:\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n","    return bool(self._sequence)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n","    return any(self)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n","    return (c for c in iterator if id(c) not in self._incompatible_ids)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n","    candidate = func()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n","    self._link_candidate_cache[link] = LinkCandidate(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n","    super().__init__(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n","    self.dist = self._prepare()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n","    dist = self._prepare_distribution()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n","    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in prepare_linked_requirement\n","    return self._prepare_linked_requirement(req, parallel_builds)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 587, in _prepare_linked_requirement\n","    local_file = unpack_url(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 166, in unpack_url\n","    file = get_http_url(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 109, in get_http_url\n","    hashes.check_against_path(from_path)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/hashes.py\", line 106, in check_against_path\n","    return self.check_against_file(file)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/hashes.py\", line 102, in check_against_file\n","    return self.check_against_chunks(read_chunks(file))\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/hashes.py\", line 86, in check_against_chunks\n","    hash.update(chunk)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n","    return run(options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n","    logger.debug(\"Exception information:\", exc_info=True)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n","    self._log(DEBUG, msg, args, **kwargs)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n","    self.emit(record)\n","  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n","    logging.FileHandler.emit(self, record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n","    StreamHandler.emit(self, record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n","    return fmt.format(record)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n","    formatted = super().format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n","    record.exc_text = self.formatException(record.exc_info)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n","    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n","  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n","    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n","  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n","    self.stack = StackSummary.extract(\n","  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n","    f.line\n","  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n","    self._line = linecache.getline(self.filename, self.lineno)\n","  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n","    lines = getlines(filename, module_globals)\n","  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n","    return updatecache(filename, module_globals)\n","  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n","    with tokenize.open(fullname) as fp:\n","  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n","    encoding, lines = detect_encoding(buffer.readline)\n","  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n","    first = read_or_stop()\n","  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n","    return readline()\n","KeyboardInterrupt\n","^C\n","Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tDXFuXcwcNix","colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"status":"error","timestamp":1715101835838,"user_tz":360,"elapsed":9,"user":{"displayName":"AI Student","userId":"00754387130632506558"}},"outputId":"31f767c5-d1cc-4b35-9edf-034747d0082c"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'drive/My Drive/PRETRAINING/Torrestube.txt'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-443e788ae665>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#SCRIPT PARA ENTRENAR EL MODELO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/PRETRAINING/Torrestube.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/PRETRAINING/Torrestube.txt'"]}],"source":["#SCRIPT PARA ENTRENAR EL MODELO\n","\n","with open('drive/My Drive/PRETRAINING/Torrestube.txt', 'r', encoding='utf-8') as f:\n","    texto = f.read()\n","\n","# hiperparámetros\n","tamaño_lote = 32 # secuencias independientes para procesar en paralelo\n","tamaño_bloque = 64 # longitud máxima del contexto para predicciones\n","max_iters = 10000\n","intervalo_evaluacion = 200\n","tasa_aprendizaje = 1e-3\n","eval_iters = 200\n","n_embd = 64\n","n_head = 4\n","n_capa = 4\n","dropout = 0.0\n","dispositivo = 'cuda' if torch.cuda.is_available() else 'cpu' # usar GPU si está disponible\n","# ------------\n","\n","\n","\n","# Caracteres únicos que ocurren en este texto\n","caracteres = sorted(list(set(texto)))\n","tamaño_vocabulario = len(caracteres)\n","\n","# Crea un mapeo de caracteres a enteros\n","caracteres_a_enteros = { ch:i for i,ch in enumerate(caracteres) }\n","enteros_a_caracteres = { i:ch for i,ch in enumerate(caracteres) }\n","codificar = lambda s: [caracteres_a_enteros[c] for c in s] # codificador: tomar una cadena, producir una lista de enteros\n","decodificar = lambda l: ''.join([enteros_a_caracteres[i] for i in l]) # decodificador: tomar una lista de enteros, producir una cadena\n","\n","# Divisiones de entrenamiento y prueba\n","datos = torch.tensor(codificar(texto), dtype=torch.long)\n","n = int(0.9*len(datos)) # el primer 90% será entrenamiento, el resto validación\n","datos_entrenamiento = datos[:n]\n","datos_validacion = datos[n:]\n","\n","torch.manual_seed(5483)\n","\n","# carga de datos\n","def obtener_lote(division):\n","    # generar un pequeño lote de datos de entradas x y objetivos y\n","    datos = datos_entrenamiento if division == 'train' else datos_validacion\n","    ix = torch.randint(len(datos) - tamaño_bloque, (tamaño_lote,))\n","    x = torch.stack([datos[i:i+tamaño_bloque] for i in ix])\n","    y = torch.stack([datos[i+1:i+tamaño_bloque+1] for i in ix])\n","    x, y = x.to(dispositivo), y.to(dispositivo)\n","    return x, y\n","\n","@torch.no_grad()\n","def estimar_perdida():\n","    out = {}\n","    modelo.eval()\n","    for division in ['train', 'val']:\n","        perdidas = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = obtener_lote(division)\n","            logits, perdida = modelo(X, Y)\n","            perdidas[k] = perdida.item()\n","        out[division] = perdidas.mean()\n","    modelo.train()\n","    return out\n","\n","class Cabeza(nn.Module):\n","    \"\"\" una cabeza de autoatención \"\"\"\n","\n","    def __init__(self, tamaño_cabeza):\n","        super().__init__()\n","        self.clave = nn.Linear(n_embd, tamaño_cabeza, bias=False)\n","        self.consulta = nn.Linear(n_embd, tamaño_cabeza, bias=False)\n","        self.valor = nn.Linear(n_embd, tamaño_cabeza, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(tamaño_bloque, tamaño_bloque)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.clave(x)   # (B,T,C)\n","        q = self.consulta(x) # (B,T,C)\n","        # calcular puntajes de atención (\"afinidades\")\n","        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T)\n","        wei = self.dropout(wei)\n","        # realizar la agregación ponderada de los valores\n","        v = self.valor(x) # (B,T,C)\n","        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n","        return out\n","\n","class AtencionMultiCabeza(nn.Module):\n","    \"\"\" múltiples cabezas de autoatención en paralelo \"\"\"\n","\n","    def __init__(self, num_cabezas, tamaño_cabeza):\n","        super().__init__()\n","        self.cabezas = nn.ModuleList([Cabeza(tamaño_cabeza) for _ in range(num_cabezas)])\n","        self.proy = nn.Linear(n_embd, n_embd)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.cabezas], dim=-1)\n","        out = self.dropout(self.proy(out))\n","        return out\n","\n","class FeedForward(nn.Module):\n","    \"\"\" una capa lineal seguida de una no-linealidad \"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.red = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.red(x)\n","\n","class Bloque(nn.Module):\n","    \"\"\" Bloque transformador: comunicación seguida de cálculo \"\"\"\n","\n","    def __init__(self, n_embd, n_cabeza):\n","        # n_embd: dimensión del embedding, n_cabeza: el número de cabezas que nos gustaría\n","        super().__init__()\n","        tamaño_cabeza = n_embd // n_cabeza\n","        self.atn = AtencionMultiCabeza(n_cabeza, tamaño_cabeza)\n","        self.avance = FeedForward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        x = x + self.atn(self.ln1(x))\n","        x = x + self.avance(self.ln2(x))\n","        return x\n","\n","# modelo bigrama simple\n","class ModeloBigrama(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        # cada token lee directamente los logits para el siguiente token desde una tabla de búsqueda\n","        self.tabla_embedding_token = nn.Embedding(tamaño_vocabulario, n_embd)\n","        self.tabla_embedding_posición = nn.Embedding(tamaño_bloque, n_embd)\n","        self.bloques = nn.Sequential(*[Bloque(n_embd, n_cabeza=n_head) for _ in range(n_capa)])\n","        self.ln_f = nn.LayerNorm(n_embd) # capa final de normalización\n","        self.cabeza_lm = nn.Linear(n_embd, tamaño_vocabulario)\n","\n","    def forward(self, idx, objetivos=None):\n","        B, T = idx.shape\n","\n","        # idx y objetivos son ambos tensores (B, T) de enteros\n","        emb_tok = self.tabla_embedding_token(idx) # (B,T,C)\n","        emb_pos = self.tabla_embedding_posición(torch.arange(T, device=dispositivo)) # (T,C)\n","        x = emb_tok + emb_pos # (B,T,C)\n","        x = self.bloques(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.cabeza_lm(x) # (B,T,tamaño_vocabulario)\n","\n","        if objetivos is None:\n","            perdida = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            objetivos = objetivos.view(B*T)\n","            perdida = F.cross_entropy(logits, objetivos)\n","\n","        return logits, perdida\n","\n","    def generar(self, idx, máx_nuevos_tokens):\n","        # idx es un arreglo (B, T) de índices en el contexto actual\n","        for _ in range(máx_nuevos_tokens):\n","            # recortar idx a los últimos tamaño_bloque tokens\n","            idx_cond = idx[:, -tamaño_bloque:]\n","            # obtener las predicciones\n","            logits, perdida = self(idx_cond)\n","            # enfocarse solo en el último paso de tiempo\n","            logits = logits[:, -1, :] # se convierte en (B, C)\n","            # aplicar softmax para obtener probabilidades\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # muestrear de la distribución\n","            idx_siguiente = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # agregar el índice muestreado a la secuencia en ejecución\n","            idx = torch.cat((idx, idx_siguiente), dim=1) # (B, T+1)\n","        return idx\n","\n","# imprimir el número de parámetros en el modelo\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parámetros')\n","\n","modelo = ModeloBigrama()\n","m = modelo.to(dispositivo)\n","# crear un optimizador PyTorch\n","optimizador = torch.optim.AdamW(modelo.parameters(), lr=tasa_aprendizaje)\n","\n","for iteracion in range(max_iters):\n","\n","    # cada cierto tiempo evaluar la pérdida en los conjuntos de entrenamiento y validación\n","    if iteracion % intervalo_evaluacion == 0 or iteracion == max_iters - 1:\n","        perdidas = estimar_perdida()\n","        print(f\"paso {iteracion}: pérdida de entrenamiento {perdidas['train']:.4f}, pérdida de validación {perdidas['val']:.4f}\")\n","\n","    # obtener un lote de datos\n","    xb, yb = obtener_lote('train')\n","\n","    # evaluar la pérdida\n","    logits, perdida = modelo(xb, yb)\n","    optimizador.zero_grad(set_to_none=True)\n","    perdida.backward()\n","    optimizador.step()\n","\n","torch.save(modelo.state_dict(), 'drive/My Drive/PRETRAINING/torrestmodelo.pth')\n","\n","contexto = torch.zeros((1, 1), dtype=torch.long, device=dispositivo)\n","print(decodificar(m.generar(contexto, máx_nuevos_tokens=100)[0].tolist()))\n"]}]}